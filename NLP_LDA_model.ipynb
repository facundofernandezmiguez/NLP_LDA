{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"\n", "Created on Tue Oct 10 11:45:08 2023"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@author: fafernan2101\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from gensim import corpora, models\n", "from nltk.tokenize import word_tokenize\n", "from nltk.corpus import stopwords\n", "import glob\n", "import nltk\n", "nltk.download('stopwords')\n", "nltk.download('punkt')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cargar los archivos csv"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ruta = 'C:/Users/Fafernan2101/Desktop/Ejercicio/corpus/*.csv'  \n", "archivos = glob.glob(ruta)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Crear una lista para almacenar los textos"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["textos = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for archivo in archivos:\n", "    df = pd.read_csv(archivo, header=None , engine = 'python', sep=';')\n", "    # Seleccionar solo la primera mitad de las filas\n", "    texto = ' '.join(df.iloc[1].dropna().tolist())  # Concatena el contenido de todas las columnas en la segunda fila\n", "    textos.append(texto)\n", "    \n", "# Preprocesamiento: tokenizaci\u00c3\u00b3n y eliminaci\u00c3\u00b3n de palabras vac\u00c3\u00adas\n", "stop_words = set(stopwords.words('spanish'))\n", "# Agregar palabras adicionales a la lista de palabras vac\u00c3\u00adas\n", "palabras_adicionales = ['hola', 'si', 'al\u00c3\u00b3','muchas', 'gracias', 'buenas', 'tardes', 'disculpe','se\u00c3\u00b1ora','habla', 'buenos', 'voy','perfecto','claro','n\u00c3\u00bamero','dias', 'usted', 'mire', 'mira', 'entonces','favor','d\u00c3\u00ada','okay','aqu\u00c3\u00ad','ah\u00c3\u00ad','nombre',\n", "                        'cero','uno', 'dos', 'tres','cuatro' , 'cinco' , 'seis','siete','ocho','nueve','diez','catorce','quince','treinta','cuarenta','cincuenta','noventa','mil']\n", "stop_words.update(palabras_adicionales)\n", "textos_procesados = [[word for word in word_tokenize(texto.lower()) if word.isalpha() and word not in stop_words] for texto in textos] "]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "alpha : controls per-document topic distribution <br>\n", "beta controls per topic word distribution<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Visualizarion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from wordcloud import WordCloud\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Concatena todos los textos en una sola cadena"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["texto = ' '.join([' '.join(texto) for texto in textos_procesados])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Crea la nube de palabras"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["wordcloud = WordCloud(width = 1000, height = 500).generate(texto)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Muestra la nube de palabras"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,8))\n", "plt.imshow(wordcloud)\n", "plt.axis(\"off\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Crear un diccionario y un corpus para el modelado de t\u00c3\u00b3picos"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["diccionario = corpora.Dictionary(textos_procesados)\n", "corpus = [diccionario.doc2bow(texto) for texto in textos_procesados]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Entrenar el modelo LDA"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lda_model = models.LdaModel(corpus, num_topics=15, id2word=diccionario, passes=100 , alpha = 0.01 , eta = 0.0001 , iterations = 100)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Imprimir los t\u00c3\u00b3picos"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["topics = lda_model.print_topics(num_words=8)\n", "for topic in topics:\n", "    print(topic)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pyLDAvis\n", "import pyLDAvis.gensim_models"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Habilita la visualizaci\u00c3\u00b3n en el notebook"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pyLDAvis.enable_notebook()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Prepara los datos de visualizaci\u00c3\u00b3n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, diccionario)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Muestra la visualizaci\u00c3\u00b3n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vis"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}